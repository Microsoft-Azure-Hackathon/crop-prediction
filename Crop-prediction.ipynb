{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb661ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploying model\n",
    "script_file = \"crop_predict.py\"\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    return json.dumps(predictions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c730322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model model\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace(subscription_id=\"7b7e94ec-f305-433f-829b-475500f5b6b3\",\n",
    "               resource_group=\"KS_hack_2022\",\n",
    "               workspace_name=\"KS_reactor_hack\")\n",
    "\n",
    "# Register model\n",
    "model = Model.register(ws, model_name=\"model\", model_path=\"./model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7a877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment(name=\"project_environment\")\n",
    "dummy_inference_config = InferenceConfig(\n",
    "    environment=env,\n",
    "    source_directory=\"./source_dir\",\n",
    "    entry_script=\"./echo_score.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ce467d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd336f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "service = Model.deploy(\n",
    "    ws,\n",
    "    \"myservice\",\n",
    "    [model],\n",
    "    dummy_inference_config,\n",
    "    deployment_config,\n",
    "    overwrite=True,\n",
    ")\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aaa4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "625126ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Environment' object has no attribute 'python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m ml_client\u001b[38;5;241m.\u001b[39menvironments\u001b[38;5;241m.\u001b[39mcreate_or_update(env_docker_conda)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Configure the scoring environment\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m inference_config \u001b[38;5;241m=\u001b[39m \u001b[43mInferenceConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry_script\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscript_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_docker_conda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m deployment_config \u001b[38;5;241m=\u001b[39m AciWebservice\u001b[38;5;241m.\u001b[39mdeploy_configuration(cpu_cores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, memory_gb \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m service_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrop_predict-service\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py:2129\u001b[0m, in \u001b[0;36mInferenceConfig.__init__\u001b[0;34m(self, entry_script, runtime, conda_file, extra_docker_file_steps, source_directory, enable_gpu, description, base_image, base_image_registry, cuda_version, environment)\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_image_registry \u001b[38;5;241m=\u001b[39m base_image_registry \u001b[38;5;129;01mor\u001b[39;00m ContainerRegistry()\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment \u001b[38;5;241m=\u001b[39m environment\n\u001b[0;32m-> 2129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py:2217\u001b[0m, in \u001b[0;36mInferenceConfig.validate_configuration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconda_file \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_docker_file_steps \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m   2213\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_gpu \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_version \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_image:\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WebserviceException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError, unable to provide runtime, conda_file, extra_docker_file_steps, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2215\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menable_gpu, cuda_version, or base_image along with an environment object.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython\u001b[49m\u001b[38;5;241m.\u001b[39mconda_dependencies \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m   2218\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mazureml-defaults\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39mconda_dependencies\u001b[38;5;241m.\u001b[39mserialize_to_string():\n\u001b[1;32m   2219\u001b[0m     module_logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarning, azureml-defaults not detected in provided environment pip \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2220\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdependencies. The azureml-defaults package contains requirements for the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2221\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference stack to run, and should be included.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mdocker\u001b[38;5;241m.\u001b[39mbase_dockerfile \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mdocker\u001b[38;5;241m.\u001b[39mbase_image:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Environment' object has no attribute 'python'"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azure.ai.ml import MLClient\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "#Enter details of your AzureML workspace\n",
    "subscription_id = '7b7e94ec-f305-433f-829b-475500f5b6b3'\n",
    "resource_group = 'KS_hack_2022'\n",
    "workspace = 'KS_reactor_hack'\n",
    "\n",
    "#connect to the workspace\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    conda_file=\"environment.yml\",\n",
    "    name=\"docker-image-plus-conda-example\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_conda)\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(entry_script=script_file,\n",
    "                                   environment=env_docker_conda)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"crop_predict-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a34532",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_file = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/rlsri23051/code/Users/rlsri2305/score_crop.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81eddbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/rlsri23051/code/Users/rlsri2305/score_crop.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    return json.dumps(predictions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b1dd4be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m ml_client \u001b[38;5;241m=\u001b[39m MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\n\u001b[1;32m     19\u001b[0m ws \u001b[38;5;241m=\u001b[39m Workspace(subscription_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7b7e94ec-f305-433f-829b-475500f5b6b3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m                resource_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKS_hack_2022\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m                workspace_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKS_reactor_hack\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvironment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpython\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mazureml_py310_sdkv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconda_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menvironment.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocker-image-plus-conda-example\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnvironment created from a Docker image plus Conda environment.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m ml_client\u001b[38;5;241m.\u001b[39menvironments\u001b[38;5;241m.\u001b[39mcreate_or_update(env)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Configure the scoring environment\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/entities/_assets/environment.py:113\u001b[0m, in \u001b[0;36mEnvironment.__init__\u001b[0;34m(self, name, version, description, image, build, conda_file, tags, properties, datastore, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m inference_config \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    111\u001b[0m os_type \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconda_file \u001b[38;5;241m=\u001b[39m conda_file\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m image\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/entities/_assets/asset.py:66\u001b[0m, in \u001b[0;36mAsset.__init__\u001b[0;34m(self, name, version, description, tags, properties, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     err \u001b[38;5;241m=\u001b[39m ValidationException(\n\u001b[1;32m     58\u001b[0m         message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m     59\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mASSET,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m         error_type\u001b[38;5;241m=\u001b[39mValidationErrorType\u001b[38;5;241m.\u001b[39mMISSING_FIELD,\n\u001b[1;32m     63\u001b[0m     )\n\u001b[1;32m     64\u001b[0m     log_and_raise_error(err)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m version\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/entities/_resource.py:60\u001b[0m, in \u001b[0;36mResource.__init__\u001b[0;34m(self, name, description, tags, properties, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize \u001b[38;5;241m=\u001b[39m Serializer(client_models)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize\u001b[38;5;241m.\u001b[39mclient_side_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace\n",
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "#import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command, Input\n",
    "\n",
    "#Enter details of your AzureML workspace\n",
    "subscription_id = '7b7e94ec-f305-433f-829b-475500f5b6b3'\n",
    "resource_group = 'KS_hack_2022'\n",
    "workspace = 'KS_reactor_hack'\n",
    "\n",
    "#connect to the workspace\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\n",
    "\n",
    "ws = Workspace(subscription_id=\"7b7e94ec-f305-433f-829b-475500f5b6b3\",\n",
    "               resource_group=\"KS_hack_2022\",\n",
    "               workspace_name=\"KS_reactor_hack\")\n",
    "\n",
    "env = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    python=\"azureml_py310_sdkv2\",\n",
    "    conda_file=\"environment.yml\",\n",
    "    name=\"docker-image-plus-conda-example\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    "    \n",
    ")\n",
    "ml_client.environments.create_or_update(env)\n",
    "\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(entry_script=script_file,\n",
    "                                   environment=env)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"croppredict-service3\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65193104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
